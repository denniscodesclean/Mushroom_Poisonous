# -*- coding: utf-8 -*-
"""Mushroom.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DesisUE87ziishYkefUKwvrtHR3dFke7
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import lightgbm as lgb
from lightgbm import LGBMClassifier
import xgboost as xgb
from xgboost import XGBClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, precision_score, recall_score, matthews_corrcoef

"""#Load Data"""

def load_data(path):
  data = pd.read_csv(path)
  return data

train = load_data('/content/drive/My Drive/Colab Notebooks/PoisonousMushroom/train.csv')
test = load_data('/content/drive/My Drive/Colab Notebooks/PoisonousMushroom/test.csv')

print(train.shape)
print(test.shape)

"""#EDA

"""

print('=== Train ===\n')
print(round(train.isna().sum()/train.shape[0]*100,4))
print('\n=== Test ===\n')
print(round(test.isna().sum()/train.shape[0]*100,4))

#
col_by_type = {
   dtypes: train.drop(['id'],axis=1).select_dtypes(include=dtypes).columns for dtypes in ['number','object']
}

# Plot numerical columns
for col in col_by_type['number']:
    plt.figure()
    sns.histplot(train[col], kde=True, bins=10)
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.show()

# Plot categorical columns
for col in col_by_type['object']:
    plt.figure()
    sns.countplot(x=train[col])
    plt.title(f'Count of {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.show()

"""There's no significant class imbalance.

Categorical columns clusters in some top values.
"""

sns.pairplot(train.drop(['id'],axis=1).select_dtypes(include='number'))
plt.show()

"""# Missing Value Handling"""

def missing_value(train,test):
  '''
  Return missing value in train or test set;
  Return missing columns that are in only train or test set;
  Return associated dtypes.
  '''
  # count % of missing value
  df_train = pd.DataFrame(round(train.isna().sum()/train.shape[0]*100,4)).reset_index()
  df_train.columns=['column','missing value %']
  df_test = pd.DataFrame(round(test.isna().sum()/train.shape[0]*100,4)).reset_index()
  df_test.columns=['column','missing value %']

  # data types
  dtype = train.dtypes.reset_index().rename(columns={'index':'column',0:'type'})

  # join train, test
  result = pd.merge(df_train, df_test, how='outer',on='column')
  result.columns=['column','train_missing_%','test_missing_%']

  missing = result[(result['train_missing_%']>0)|
    (result['test_missing_%']>0)
    |(result['test_missing_%'].isna())
    |(result['train_missing_%'].isna())]

  # join dtypes
  output = pd.merge(missing, dtype, how='inner', on='column')

  return output.sort_values(by='train_missing_%',ascending=False)

miss = missing_value(train,test)
miss

"""#Base line Model

"""

X_train = train.drop(['id','class'],axis=1)
y_train = train['class'].replace({'e':0,'p':1})

# convert object to category
cat_cols = list(X_train.select_dtypes('object').columns)
X_train[cat_cols] = X_train[cat_cols].astype('category')

# Load Data
dtrain = xgb.DMatrix(data=X_train, label=y_train, enable_categorical=True)


# Define parameters for cross-validation
params = {
    'objective': 'binary:logistic',
    'max_depth': 5,
    'learning_rate': 0.1,
    'eval_metric': 'auc',
    'tree_method': 'hist',  # necessary for categorical data
}

cv_results = xgb.cv(
    params=params,
    dtrain=dtrain,
    num_boost_round=100,
    nfold=5,
    stratified=True,
    early_stopping_rounds=10,
    as_pandas=True,
    verbose_eval=True,
    random_state=123
)

print(cv_results)

# Get the best booster from cross-validation
best_round = cv_results['test-auc-mean'].idxmax()

# Retrain the model using the best boosting round
best_model = xgb.train(
    params=params,
    dtrain=dtrain,
    num_boost_round=best_round
)

# Make predictions with the best booster
y_pred = best_model.predict(dtrain)

# Convert predictions to binary (0 or 1)
y_pred_binary = (y_pred > 0.5).astype(int)

# Calculate precision and recall
precision = precision_score(y_train, y_pred_binary)
recall = recall_score(y_train, y_pred_binary)
roc_auc = roc_auc_score(y_train,y_pred)
mcc = matthews_corrcoef(y_train, y_pred)

print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'ROC AUC: {roc_auc}')
print(f'Matthews Correlation Coefficient (MCC): {mcc}')

# Feature importance
importance = best_model.get_score(importance_type='weight')
fi = pd.DataFrame(importance.items())
fi.columns = ['column', 'importance']
fi.sort_values(by='importance',ascending=False)

output = pd.merge(miss,fi,how='left',on='column')
output

"""Scenario 1:
- Feature is Highly Missing but Not Important
- Action: Drop feature from model

Scenario 2:
- Feature is Highly Missing but Important
- Action: Exploring imputing

Scenario 3:
- Feature is Not Missing
- Action: Keep

"""

